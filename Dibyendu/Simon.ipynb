{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534036011.477325\n",
      "Starting LightGBM. Train shape: (307511, 108), test shape: (0, 108)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.74254\tvalid_1's auc: 0.734289\n",
      "[200]\ttraining's auc: 0.754817\tvalid_1's auc: 0.741823\n",
      "[300]\ttraining's auc: 0.764538\tvalid_1's auc: 0.746458\n",
      "[400]\ttraining's auc: 0.772089\tvalid_1's auc: 0.749356\n",
      "[500]\ttraining's auc: 0.77767\tvalid_1's auc: 0.75099\n",
      "[600]\ttraining's auc: 0.782607\tvalid_1's auc: 0.752241\n",
      "[700]\ttraining's auc: 0.787075\tvalid_1's auc: 0.753018\n",
      "[800]\ttraining's auc: 0.79096\tvalid_1's auc: 0.753426\n",
      "[900]\ttraining's auc: 0.794526\tvalid_1's auc: 0.753817\n",
      "[1000]\ttraining's auc: 0.797651\tvalid_1's auc: 0.754018\n",
      "[1100]\ttraining's auc: 0.800728\tvalid_1's auc: 0.754108\n",
      "[1200]\ttraining's auc: 0.803433\tvalid_1's auc: 0.754194\n",
      "[1300]\ttraining's auc: 0.806234\tvalid_1's auc: 0.754207\n",
      "[1400]\ttraining's auc: 0.80895\tvalid_1's auc: 0.754212\n",
      "Early stopping, best iteration is:\n",
      "[1234]\ttraining's auc: 0.804379\tvalid_1's auc: 0.754242\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input data must be 2 dimensional and non empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6cd0448e09c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full model run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-6cd0448e09c2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(debug, num_folds)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run LightGBM plus kfold {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mfeature_importance_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mkfold_lightgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mtest_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mdisplay_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_importance_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6cd0448e09c2>\u001b[0m in \u001b[0;36mkfold_lightgbm\u001b[0;34m(train_df, test_df, num_folds, stratified, debug)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         sub_preds += clf.predict_proba(test_df[feats], \n\u001b[0;32m---> 92\u001b[0;31m                                        num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \"\"\"\n\u001b[1;32m    741\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[0;32m--> 742\u001b[0;31m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m    527\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m--> 528\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, pred_parameter, **kwargs)\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_has_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_leaf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input data must be 2 dimensional and non empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input data must be 2 dimensional and non empty."
     ]
    }
   ],
   "source": [
    "# HOME CREDIT DEFAULT RISK COMPETITION\n",
    "# Most features are created by applying min, max, mean, sum and var functions to grouped tables.\n",
    "# Little feature selection is done and overfitting might be a problem since many features are related.\n",
    "# The following key ideas were used:\n",
    "# - Divide or subtract important features to get rates (like annuity and income)\n",
    "# - In Bureau Data: create specific features for Active credits and Closed credits\n",
    "# - In Previous Applications: create specific features for Approved and Refused applications\n",
    "# - Modularity: one function for each table (except bureau_balance and application_test)\n",
    "# - One-hot encoding for categorical features\n",
    "# All tables are joined with the application DF using the SK_ID_CURR key (except bureau_balance).\n",
    "\n",
    "# You can use LightGBM with KFold or Stratified KFold. Please upvote if you find usefull, thanks!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "# import fancyimpute\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "PATH ='../../data'\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "\n",
    "def kfold_lightgbm(train_df, test_df, num_folds, stratified=False, debug=False):\n",
    "\n",
    "    # Divide in training/validation and test data\n",
    "    #train_df = df[df['TARGET'].notnull()]\n",
    "    #test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    #del df\n",
    "    gc.collect()\n",
    "    \n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    \n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns \n",
    "             if f not in ['TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index']]\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000, \n",
    "            learning_rate=0.01,\n",
    "            num_leaves=50,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.001, \n",
    "            reg_lambda=0.01,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                eval_metric='auc', \n",
    "                verbose=100, \n",
    "                early_stopping_rounds=200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, \n",
    "                                                 num_iteration=clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        sub_preds += clf.predict_proba(test_df[feats], \n",
    "                                       num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "        \n",
    "        test_df['TARGET'] = sub_preds\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "\n",
    "    return feature_importance_df, test_df[['SK_ID_CURR', 'TARGET']]\n",
    "\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_, save=True):\n",
    "    \n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]]\\\n",
    "    .groupby(\"feature\")\\\n",
    "    .mean()\\\n",
    "    .sort_values(by=\"importance\",\n",
    "                 ascending=False)[:40]\\\n",
    "    .index\n",
    "    \n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", \n",
    "                data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    \n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if (save):\n",
    "        dt = time.time()\n",
    "        plt.savefig('lgbm_importances_{0}.png'.format(dt))\n",
    "\n",
    "\n",
    "def main(debug=True, num_folds=2):\n",
    "\n",
    "    df = pd.read_pickle('application_ext_all.pkl')\n",
    "    # df_train = pd.read_csv('application_train.csv')\n",
    "    # df_test = pd.read_csv('application_test.csv')\n",
    "    df_train = df[df['TARGET'].notnull()]\n",
    "    df_test  = df[df['TARGET'].isnull()]\n",
    "    del df\n",
    "    \n",
    "    ## START DM ##\n",
    "    \n",
    "    # Train# \n",
    "    \n",
    "    # NULL COLUMNS\n",
    "    has_null = [col for col in df_train.columns \n",
    "                if sum(df_train[col].isnull())]\n",
    "    \n",
    "    # numerical\n",
    "    has_null_num = [col for col in has_null \n",
    "                    if df_train[col].dtype == 'float']\n",
    "    \n",
    "    # categorical\n",
    "    has_null_cat = [col for col in has_null \n",
    "                    if df_train[col].dtype == 'object']\n",
    "    \n",
    "    # IMPUTE\n",
    "    # impute with mean\n",
    "    for col in has_null_num:\n",
    "        df_train[col] = df_train[col].fillna(df_train[col].mean())\n",
    "    # impute with default value\n",
    "    # for col in has_null_cat:\n",
    "        # df[col] = df[col].fillna('unknown_'+col)\n",
    "        \n",
    "    # ENCODING\n",
    "    col_cat = [col for col in df_train.columns\n",
    "               if df_train[col].dtype == 'object']\n",
    "    \n",
    "    for col in col_cat:\n",
    "        dummy = pd.get_dummies(df_train[col], \n",
    "                               prefix=col, \n",
    "                               drop_first=True)    \n",
    "\n",
    "        df_train = df_train.join(dummy)\n",
    "        del dummy\n",
    "    gc.collect()\n",
    "    df_train = df_train.drop(col_cat, axis=1)  \n",
    "    \n",
    "#    X = fancyimpute.MICE().complete(df_train)\n",
    "#    df_train = pd.DataFrame(X, columns=df_train.columns)\n",
    "#    del X\n",
    "    \n",
    "    # Test #  \n",
    "    \n",
    "    # NULL COLUMNS\n",
    "    has_null = [col for col in df_test.columns \n",
    "                if sum(df_test[col].isnull())]\n",
    "    \n",
    "    # numerical\n",
    "    has_null_num = [col for col in has_null \n",
    "                    if df_test[col].dtype == 'float']\n",
    "    \n",
    "    # categorical\n",
    "    has_null_cat = [col for col in has_null \n",
    "                    if df_test[col].dtype == 'object']\n",
    "    \n",
    "    # IMPUTE\n",
    "    # impute with mean\n",
    "    for col in has_null_num:\n",
    "        df_test[col] = df_test[col].fillna(df_test[col].mean())\n",
    "    # impute with default value\n",
    "    # for col in has_null_cat:\n",
    "    #     df[col] = df[col].fillna('unknown_'+col)\n",
    "        \n",
    "    # ENCODING\n",
    "    col_cat = [col for col in df_test.columns\n",
    "               if df_test[col].dtype == 'object']\n",
    "   \n",
    "    for col in col_cat:\n",
    "        dummy = pd.get_dummies(df_test[col], \n",
    "                               prefix=col, \n",
    "                               drop_first=True)    \n",
    "\n",
    "        df_test = df_test.join(dummy)\n",
    "        del dummy\n",
    "    gc.collect()\n",
    "    df_test = df_test.drop(col_cat, axis=1)\n",
    "    \n",
    "#    X = fancyimpute.MICE().complete(df_test)\n",
    "#    df_test = pd.DataFrame(X, columns=df_test.columns)\n",
    "#    del X\n",
    "    \n",
    "    df_test['TARGET'] = 0\n",
    "    missing_list = list(set(df_train.columns) - set(df_test.columns))\n",
    "    df_train = df_train.drop(missing_list, axis=1)\n",
    "    \n",
    "#    ones = (df_train['TARGET'] == 1).sum()\n",
    "#    df_0 = df_train[df_train['TARGET'] == 0].sample(ones)\n",
    "#    df_train_sub = df_0.append(df_train[df_train['TARGET'] == 1])\n",
    "#    del df_0\n",
    "    \n",
    "    ## END DM ##\n",
    "    \n",
    "    with timer(\"Run LightGBM plus kfold {0}\".format(num_folds)):\n",
    "        feature_importance_df, test_preds = \\\n",
    "        kfold_lightgbm(df_train, df_test, num_folds=5, stratified=True, debug=debug)\n",
    "        test_preds.to_csv('submission_{}.csv'.format(time.time()), index=False)\n",
    "        display_importances(feature_importance_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"{0}\".format(time.time()))\n",
    "    with timer(\"Full model run\"):\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('combined_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('combined_data_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
