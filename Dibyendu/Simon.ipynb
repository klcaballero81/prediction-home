{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOME CREDIT DEFAULT RISK COMPETITION\n",
    "# Most features are created by applying min, max, mean, sum and var functions to grouped tables.\n",
    "# Little feature selection is done and overfitting might be a problem since many features are related.\n",
    "# The following key ideas were used:\n",
    "# - Divide or subtract important features to get rates (like annuity and income)\n",
    "# - In Bureau Data: create specific features for Active credits and Closed credits\n",
    "# - In Previous Applications: create specific features for Approved and Refused applications\n",
    "# - Modularity: one function for each table (except bureau_balance and application_test)\n",
    "# - One-hot encoding for categorical features\n",
    "# All tables are joined with the application DF using the SK_ID_CURR key (except bureau_balance).\n",
    "\n",
    "# You can use LightGBM with KFold or Stratified KFold. Please upvote if you find usefull, thanks!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "import fancyimpute\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "PATH ='../../data'\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "\n",
    "def kfold_lightgbm(train_df, test_df, num_folds, stratified=False, debug=False):\n",
    "\n",
    "    # Divide in training/validation and test data\n",
    "    #train_df = df[df['TARGET'].notnull()]\n",
    "    #test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    #del df\n",
    "    gc.collect()\n",
    "    \n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    \n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns \n",
    "             if f not in ['TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index']]\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000, \n",
    "            learning_rate=0.01,\n",
    "            num_leaves=50,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.001, \n",
    "            reg_lambda=0.01,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                eval_metric='auc', \n",
    "                verbose=100, \n",
    "                early_stopping_rounds=200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, \n",
    "                                                 num_iteration=clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        sub_preds += clf.predict_proba(test_df[feats], \n",
    "                                       num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "        \n",
    "        test_df['TARGET'] = sub_preds\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "\n",
    "    return feature_importance_df, test_df[['SK_ID_CURR', 'TARGET']]\n",
    "\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_, save=True):\n",
    "    \n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]]\\\n",
    "    .groupby(\"feature\")\\\n",
    "    .mean()\\\n",
    "    .sort_values(by=\"importance\",\n",
    "                 ascending=False)[:40]\\\n",
    "    .index\n",
    "    \n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", \n",
    "                data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    \n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if (save):\n",
    "        dt = time.time()\n",
    "        plt.savefig('lgbm_importances_{0}.png'.format(dt))\n",
    "\n",
    "\n",
    "def main(debug=True, num_folds=2):\n",
    "\n",
    "    # df = pd.read_pickle('combined_data.pkl')\n",
    "    df_train = pd.read_csv('application_train.csv')\n",
    "    df_test = pd.read_csv('application_test.csv')\n",
    "    \n",
    "    ## START DM ##\n",
    "    \n",
    "    # Train# \n",
    "    \n",
    "    # NULL COLUMNS\n",
    "    has_null = [col for col in df_train.columns \n",
    "                if sum(df_train[col].isnull())]\n",
    "    \n",
    "    # numerical\n",
    "    has_null_num = [col for col in has_null \n",
    "                    if df_train[col].dtype == 'float']\n",
    "    \n",
    "    # categorical\n",
    "    has_null_cat = [col for col in has_null \n",
    "                    if df_train[col].dtype == 'object']\n",
    "    \n",
    "    # IMPUTE\n",
    "    # impute with mean\n",
    "    for col in has_null_num:\n",
    "        df_train[col] = df_train[col].fillna(df_train[col].mean())\n",
    "    # impute with default value\n",
    "    # for col in has_null_cat:\n",
    "        # df[col] = df[col].fillna('unknown_'+col)\n",
    "        \n",
    "    # ENCODING\n",
    "    col_cat = [col for col in df_train.columns\n",
    "               if df_train[col].dtype == 'object']\n",
    "    \n",
    "    for col in col_cat:\n",
    "        dummy = pd.get_dummies(df_train[col], \n",
    "                               prefix=col, \n",
    "                               drop_first=True)    \n",
    "\n",
    "        df_train = df_train.join(dummy)\n",
    "    \n",
    "    del dummy\n",
    "    gc.collect()\n",
    "    df_train = df_train.drop(col_cat, axis=1)  \n",
    "    \n",
    "#    X = fancyimpute.MICE().complete(df_train)\n",
    "#    df_train = pd.DataFrame(X, columns=df_train.columns)\n",
    "#    del X\n",
    "    \n",
    "    # Test #  \n",
    "    \n",
    "    # NULL COLUMNS\n",
    "    has_null = [col for col in df_test.columns \n",
    "                if sum(df_test[col].isnull())]\n",
    "    \n",
    "    # numerical\n",
    "    has_null_num = [col for col in has_null \n",
    "                    if df_test[col].dtype == 'float']\n",
    "    \n",
    "    # categorical\n",
    "    has_null_cat = [col for col in has_null \n",
    "                    if df_test[col].dtype == 'object']\n",
    "    \n",
    "    # IMPUTE\n",
    "    # impute with mean\n",
    "    for col in has_null_num:\n",
    "        df_test[col] = df_test[col].fillna(df_test[col].mean())\n",
    "    # impute with default value\n",
    "    # for col in has_null_cat:\n",
    "    #     df[col] = df[col].fillna('unknown_'+col)\n",
    "        \n",
    "    # ENCODING\n",
    "    col_cat = [col for col in df_test.columns\n",
    "               if df_test[col].dtype == 'object']\n",
    "   \n",
    "    for col in col_cat:\n",
    "        dummy = pd.get_dummies(df_test[col], \n",
    "                               prefix=col, \n",
    "                               drop_first=True)    \n",
    "\n",
    "        df_test = df_test.join(dummy)\n",
    "    \n",
    "    del dummy\n",
    "    gc.collect()\n",
    "    df_test = df_test.drop(col_cat, axis=1)\n",
    "    \n",
    "#    X = fancyimpute.MICE().complete(df_test)\n",
    "#    df_test = pd.DataFrame(X, columns=df_test.columns)\n",
    "#    del X\n",
    "    \n",
    "    df_test['TARGET'] = 0\n",
    "    missing_list = list(set(df_train.columns) - set(df_test.columns))\n",
    "    df_train = df_train.drop(missing_list, axis=1)\n",
    "    \n",
    "#    ones = (df_train['TARGET'] == 1).sum()\n",
    "#    df_0 = df_train[df_train['TARGET'] == 0].sample(ones)\n",
    "#    df_train_sub = df_0.append(df_train[df_train['TARGET'] == 1])\n",
    "#    del df_0\n",
    "    \n",
    "    ## END DM ##\n",
    "    \n",
    "    with timer(\"Run LightGBM plus kfold {0}\".format(num_folds)):\n",
    "        feature_importance_df, test_preds = \\\n",
    "        kfold_lightgbm(df_train, df_test, num_folds=5, stratified=False, debug=debug)\n",
    "        test_preds.to_csv('submission_{}.csv'.format(time.time()), index=False)\n",
    "        display_importances(feature_importance_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"{0}\".format(time.time()))\n",
    "    with timer(\"Full model run\"):\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
